# import libraries that are necessary to write code
import argparse
import subprocess 
import pandas as pd
import subjects_measures
    
def create_new_subject_file(ntr_task_file, subject_file):
    
    # open the ntr_task_file file using a with statement
    with open(ntr_task_file, 'r', encoding='utf-8') as f:
        
    # open subject_file file with a with statement to write to it
        with open(subject_file, 'w', encoding='utf-8') as sub_f:
            # for sub_row in sub_f:

    # create a list that can store all the subject pronunciations
            for row in f:
                row = row.strip().split()
                if(len(row) < 2):
                    continue
                    # fix concatenations and edit the pronunciations
                new_pronunciations = subjects_measures.edit_pronunciations(
                ntr_task_file, 16)
                words_dict = {row[0], row[1], new_pronunciations}
    
    # write to the second file to contain all concatenated pronunciations
     # and words
                sub_f.write(str(words_dict) + '\n')
    
    return subject_file

#args: path to subject file, path to output csv file
def process_subjects_to_csv(subject_file, output_csv):

    try:
        # Read input CSV file
        df = pd.read_csv(subject_file)
        
        # Create list to store all results
        all_results = []
        
        # Iterate through each row in the subject's data
        for index, row in df.iterrows():
            try:
                # Extract data from subject's file
                current_data = {
                    'pseudoword': row['pseudoword'],
                    'paradigm_order': row['paradigm_order'],
                    'concatenated_word': row['concatenated_word']
                }
                
                # Create temporary CSV for R script input 
                temp_input = pd.DataFrame({
                    'X0': [current_data['concatenated_word']],
                    'toolkit_pron': [current_data['concatenated_word']]  # Adjust if pronunciation differs
                })
                temp_input.to_csv('pronunciations.csv', index=False)
                
                # Run R script to generate measures
                subprocess.run(['Rscript', 'get_pseudoword_measures.R'], check=True)
                
                # Read the measures generated by R script
                measures_df = pd.read_csv('pseudoword_measures.csv')
                
                if not measures_df.empty:
                    # Combine original data with measures
                    measures_dict = measures_df.iloc[0].to_dict()
                    current_data.update(measures_dict)
                    
                    # Add to results
                    all_results.append(current_data)
                    
                    print(f"Processed pseudoword: {current_data['pseudoword']}")
                
            except Exception as e:
                print(f"Error processing row {index}: {e}")
                continue
        
        # Create final DataFrame and save to CSV
        final_df = pd.DataFrame(all_results)
        final_df.to_csv(output_csv, index=False)
        print(f"Successfully created {output_csv} with {len(all_results)} entries")
        
        return final_df
        
    except Exception as e:
        print(f"Error in process_subjects_to_csv: {e}")
        return None

def main():
    parser = argparse.ArgumentParser(
      description="Process a CSV file and create the measures for the subject.")
    parser.add_argument("input_file", help="Path to the input CSV file")
    parser.add_argument("output_file", help="Path to the output CSV file")
    parser.add_argument("final_csv", help="Path to the final output df")

    args = parser.parse_args()
    
    # generates subject file
    new_subject_file = create_new_subject_file(args.input_file, args.output_file)
    
    # additional information added and full df is created
    process_subjects_to_csv(new_subject_file, args.final_csv)

if __name__ == "__main__":
    main()

''' ran code as: 
python3 /Users/ramyanataraj/Documents/Research/research_measures/src/subject_files.py 
"/Users/ramyanataraj/Documents/Research/research_measures/subject_test_files/Final 0057_task-pw_run-1.xlsx - Hana.csv" 
"/Users/ramyanataraj/Documents/Research/research_measures/subject_test_files/Hana_generated.csv" 
"/Users/ramyanataraj/Documents/Research/research_measures/subject_test_files/final_Hana.csv" 
'''

'''
    pipeline: iterate through all subject files, 
    chain through data cleaning functions, 
    pass into process_subjects_to_csv function, 
    and specify the output csv path
'''