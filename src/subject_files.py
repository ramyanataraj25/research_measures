# import libraries that are necessary to write code
import argparse
import subprocess 
import pandas as pd
import subjects_measures
import os
    
def create_new_subject_file(ntr_task_file, subject_file):
    try: 
     # open the ntr_task_file file using a with statement
        with open(ntr_task_file, 'r', encoding='utf-8') as f:
    
        # open subject_file file with a with statement to write to it
            with open(subject_file, 'w', encoding='utf-8') as sub_f:
                # for sub_row in sub_f:
    
                # create a list that can store all the subject pronunciations
                i = 0
                for row in f:
                    
                    row = row.strip().split()
                    if(len(row) < 2):
                        continue
                    # fix concatenations and edit the pronunciations
                    new_pronunciations = subjects_measures.edit_pronunciations(
                    ntr_task_file,subject_file, 16)
                    words_dict = {row[i], row[i+1], new_pronunciations}
                    i = i + 1
        
                    # write to the second file to contain all concatenated pronunciations
                    # and words
                    sub_f.write(str(words_dict) + '\n')
                    print(subject_file)
                    return subject_file
    except FileNotFoundError:
        print(f"Error: Could not find the file at path: {ntr_task_file}")
        print(f"Current working directory: {os.getcwd()}")
        raise
    except Exception as e:
        print(f"Error while processing file: {str(e)}")
        raise
 
     


#args: path to subject file, path to output csv file
def process_subjects_to_csv(subject_file, output_csv):
    try:
        # Read input CSV file
        df = pd.read_csv(subject_file)
        
        # Clean up column names
        df.columns = df.columns.str.strip()
        
        # Create list to store all results
        all_results = []
        
        # Iterate through each row in the subject's data
        for index, row in df.iterrows():
            try:
                # Skip rows with 'noresp' or empty concatenated_word
                if pd.isna(row['Concatenate']) or row['Concatenate'] == 'noresp':
                    continue
                    
                # Extract data from subject's file
                current_data = {
                    'pseudoword': row['Pseudoword'],
                    'paradigm_order': row['Paradigm order'],
                    'concatenated_word': row['Concatenate']
                }
                
                # Create temporary CSV for R script input 
                temp_input = pd.DataFrame({
                    'X0': [current_data['concatenated_word']],
                    'toolkit_pron': [current_data['concatenated_word']]
                })
                temp_input.to_csv('pronunciations.csv', index=False)
                
                # Run R script to generate measures
                subprocess.run(['Rscript', 'src/get_pseudoword_measures.R'], check=True)
                
                # Read the measures generated by R script
                measures_df = pd.read_csv('pseudoword_measures.csv')
                
                if not measures_df.empty:
                    # Combine original data with measures
                    measures_dict = measures_df.iloc[0].to_dict()
                    current_data.update(measures_dict)
                    
                    # Add to results
                    all_results.append(current_data)
                    
                    print(f"Processed pseudoword: {current_data['pseudoword']}")
                
            except Exception as e:
                print(f"Error processing row {index}: {e}")
                continue
        
        # Create final DataFrame and save to CSV
        if all_results:
            final_df = pd.DataFrame(all_results)
            final_df.to_csv(output_csv, index=False)
            print(f"Successfully created {output_csv} with {len(all_results)} entries")
            return final_df
        else:
            print("No results were processed successfully")
            return None
        
    except Exception as e:
        print(f"Error in process_subjects_to_csv: {e}")
        return None

def main():
    parser = argparse.ArgumentParser(
        description="Process subject files listed in a CSV and create measures.")
    parser.add_argument("subjects_csv", help="Path to the CSV containing subject file paths")
    
    args = parser.parse_args()
    
    
    # Read the subjects CSV file
    subjects_df = pd.read_csv(args.subjects_csv)
    
    # Clean column names
    subjects_df.columns = subjects_df.columns.str.strip()
    
    # Process each subject
    for index, row in subjects_df.iterrows():
        subject_name = row['Subject Name']
        input_file = row['File Path']
        
        print(f"\nProcessing subject: {subject_name}")
        print(f"Input file path: {input_file}")
        
        # Generate output filenames based on subject name in current directory
        subject_generated = f"{subject_name}_generated.csv"
        final_output = f"final_{subject_name}.csv"
        
        # Generate subject file
        new_subject_file = create_new_subject_file(input_file, subject_generated)
        
        print(f"Completed processing for {subject_name}\n")
        # Process subject data and create final output
        temp = process_subjects_to_csv(new_subject_file, final_output)
        print(new_subject_file)
        
        

if __name__ == "__main__":
    main()

'''
    pipeline: iterate through all subject files, 
    chain through data cleaning functions, 
    pass into process_subjects_to_csv function, 
    and specify the output csv path
'''