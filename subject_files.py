# import libraries that are necessary to write code
import csv
import subprocess 
import pandas as pd

# read the subject file in and parse through removing "ɚɹ" the ɹ is it follows
# ɚ	or 3
def edit_pronunciations(subject_file):
    word = "" # can ingore these variables was trying to remove the error line
    return word

# take file created from previous file (so subject_file) and apply conversion 
# code to convert IPA to toolkit conventions (from Caleb)
    
def create_new_subject_file(ntr_task_file, subject_file):
    file = subject_file # this is wrong assignment just removing the error line
    
# open the ntr_task_file file using a with statement

# open subject_file file with a with statement to write to it

    # create a list that can store all the subject pronunciations
    
    # append the 'concatentate' column in order to the first list of pronunciations
    
    # write to the second file to contain all concatenated pronunciations
    # and words
    
    return file

#args: path to subject file, path to output csv file
def process_subjects_to_csv(subject_file, output_csv):
    """
        retrieve the paradigm order, pseudoword, and concatenated word from the ramya csv file
        iterate thorugh every pseudoword in csv file and call the R script to generate 
        the measures
        add these measures in the csv file 
        return the csv file 
    """

    try:
        # Read input CSV file
        df = pd.read_csv(subject_file)
        
        # Create list to store all results
        all_results = []
        
        # Iterate through each row in the subject's data
        for index, row in df.iterrows():
            try:
                # Extract data from subject's file
                current_data = {
                    'pseudoword': row['pseudoword'],
                    'paradigm_order': row['paradigm_order'],
                    'concatenated_word': row['concatenated_word']
                }
                
                # Create temporary CSV for R script input 
                temp_input = pd.DataFrame({
                    'X0': [current_data['concatenated_word']],
                    'toolkit_pron': [current_data['concatenated_word']]  # Adjust if pronunciation differs
                })
                temp_input.to_csv('pronunciations.csv', index=False)
                
                # Run R script to generate measures
                subprocess.run(['Rscript', 'get_pseudoword_measures.R'], check=True)
                
                # Read the measures generated by R script
                measures_df = pd.read_csv('pseudoword_measures.csv')
                
                if not measures_df.empty:
                    # Combine original data with measures
                    measures_dict = measures_df.iloc[0].to_dict()
                    current_data.update(measures_dict)
                    
                    # Add to results
                    all_results.append(current_data)
                    
                    print(f"Processed pseudoword: {current_data['pseudoword']}")
                
            except Exception as e:
                print(f"Error processing row {index}: {e}")
                continue
        
        # Create final DataFrame and save to CSV
        final_df = pd.DataFrame(all_results)
        final_df.to_csv(output_csv, index=False)
        print(f"Successfully created {output_csv} with {len(all_results)} entries")
        
        return final_df
        
    except Exception as e:
        print(f"Error in process_subjects_to_csv: {e}")
        return None
    

    '''
      pipeline: iterate through all subject files, 
      chain through data cleaning functions, 
      pass into process_subjects_to_csv function, 
      and specify the output csv path
    '''